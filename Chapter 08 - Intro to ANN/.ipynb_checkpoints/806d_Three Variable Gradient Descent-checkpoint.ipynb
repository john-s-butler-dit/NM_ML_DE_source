{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f70969",
   "metadata": {},
   "source": [
    "## Example Three Variable Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90b3ef",
   "metadata": {},
   "source": [
    "Consider the cost function with three variables:\n",
    "\n",
    "$$J(\\theta_1, \\theta_2, \\theta_3) = \\theta_1^2 + 2\\theta_2^2 + 3\\theta_3^2$$\n",
    "\n",
    "To minimize this cost function using gradient descent. The gradient of this cost function is as follows:\n",
    "\n",
    "$\n",
    "\\nabla J(\\theta_1, \\theta_2, \\theta_3) = \\begin{bmatrix}\n",
    "2\\theta_1 \\\\\n",
    "4\\theta_2 \\\\\n",
    "6\\theta_3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "**Initialization**:\n",
    "\n",
    "Given the inital conditions:\n",
    "\n",
    "- $\\theta_1 = 1.0$\n",
    "- $\\theta_2 = 2.0$\n",
    "- $\\theta_3 = 3.0$\n",
    "- $\\alpha = 0.1$\n",
    "\n",
    "**Iteration 1**:\n",
    "1. Calculate the gradient at the current parameters:\n",
    "\n",
    "   $\\nabla J(\\theta_1, \\theta_2, \\theta_3) = \\begin{bmatrix}\n",
    "   2 \\cdot 1.0 \\\\\n",
    "   4 \\cdot 2.0 \\\\\n",
    "   6 \\cdot 3.0\n",
    "   \\end{bmatrix} = \\begin{bmatrix}\n",
    "   2 \\\\\n",
    "   8 \\\\\n",
    "   18\n",
    "   \\end{bmatrix}$\n",
    "\n",
    "2. Update the parameters:\n",
    "\n",
    "   $\\theta_1 = \\theta_1 - \\alpha \\cdot 2 = 1.0 - 0.1 \\cdot 2 = 0.8$\n",
    "\n",
    "   $\\theta_2 = \\theta_2 - \\alpha \\cdot 8 = 2.0 - 0.1 \\cdot 8 = 1.2$\n",
    "\n",
    "   $\\theta_3 = \\theta_3 - \\alpha \\cdot 18 = 3.0 - 0.1 \\cdot 18 = 1.2$\n",
    "\n",
    "**Iteration 2**:\n",
    "1. Calculate the gradient at the updated parameters:\n",
    "\n",
    "   $\\nabla J(\\theta_1, \\theta_2, \\theta_3) = \\begin{bmatrix}\n",
    "   2 \\cdot 0.8 \\\\\n",
    "   4 \\cdot 1.2 \\\\\n",
    "   6 \\cdot 1.2\n",
    "   \\end{bmatrix} = \\begin{bmatrix}\n",
    "   1.6 \\\\\n",
    "   4.8 \\\\\n",
    "   7.2\n",
    "   \\end{bmatrix}$\n",
    "\n",
    "2. Update the parameters:\n",
    "\n",
    "   $\\theta_1 = 0.8 - 0.1 \\cdot 1.6 = 0.64$\n",
    "\n",
    "   $\\theta_2 = 1.2 - 0.1 \\cdot 4.8 = 0.72$\n",
    "\n",
    "   $\\theta_3 = 1.2 - 0.1 \\cdot 7.2 = 0.48$\n",
    "\n",
    "**Stopping Criteria**:\n",
    "\n",
    "Choose the stopping criteria tol and max iteratinos such that the algorithms stops when the parameter converges to within a tolerance $$\\Sigma_{j=0}^2|\\theta_{ji+1}-\\theta_{ji}|<tol$$\n",
    "   or the number of iterations reaches the max iterations. \n",
    "There are many possible formula for the stopping criteria the one of the most strigent is the max norm:\n",
    "$$\\max_{j}|\\theta_{ji+1}-\\theta_{ji}|<tol.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af8c37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal theta: [4.72236648e-03 9.47676268e-06 8.44424930e-10]\n",
      "Minimum Cost value: 2.2300924816594426e-05\n",
      "Number of Interations I: 24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Define the cost function\n",
    "def quadratic_cost_function(theta):\n",
    "    return theta[0]**2+2*theta[1]**2+3*theta[2]**2\n",
    "# Define the gradient\n",
    "def gradient(theta):\n",
    "    return np.array([2*theta[0],4*theta[1],6*theta[2]])\n",
    "# Gradient Descent parameters\n",
    "learning_rate = 0.1  # Step size or learning rate\n",
    "# Initial guess\n",
    "theta_0 = np.array([1,2,3])\n",
    "def gradient_descent(theta,learning_rate=0.1, tol=1e-6, max_iter=100):\n",
    "    theta_history = [theta]\n",
    "    cost_history = [quadratic_cost_function(theta)]\n",
    "    for i in range(max_iter):\n",
    "        # Update x using the gradient and learning rate\n",
    "        theta_new = theta - learning_rate * gradient(theta)\n",
    "\n",
    "        # Append the updated values to the history lists\n",
    "        theta_history.append(theta_new)\n",
    "        cost_history.append(quadratic_cost_function(theta_new))\n",
    "        if np.sum(np.abs((theta-theta_new))) < tol:\n",
    "            return theta,theta_history, cost_history,i\n",
    "        theta=theta_new\n",
    "\n",
    "    return theta,theta_history, cost_history,i\n",
    "\n",
    "tol=0.001\n",
    "max_iterations = 100     # Number of iterations\n",
    "theta, theta_history, cost_history,I=gradient_descent(theta_0,learning_rate=learning_rate,tol=tol,max_iter=max_iterations)\n",
    "# Print the final result\n",
    "print(f'Optimal theta: {theta}')\n",
    "print(f\"Minimum Cost value: {quadratic_cost_function(theta)}\")\n",
    "print(f\"Number of Interations I: {I}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaec773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3]),\n",
       " array([0.8, 1.2, 1.2]),\n",
       " array([0.64, 0.72, 0.48]),\n",
       " array([0.512, 0.432, 0.192]),\n",
       " array([0.4096, 0.2592, 0.0768]),\n",
       " array([0.32768, 0.15552, 0.03072]),\n",
       " array([0.262144, 0.093312, 0.012288]),\n",
       " array([0.2097152, 0.0559872, 0.0049152]),\n",
       " array([0.16777216, 0.03359232, 0.00196608]),\n",
       " array([0.13421773, 0.02015539, 0.00078643]),\n",
       " array([0.10737418, 0.01209324, 0.00031457]),\n",
       " array([0.08589935, 0.00725594, 0.00012583]),\n",
       " array([6.87194767e-02, 4.35356467e-03, 5.03316480e-05]),\n",
       " array([5.49755814e-02, 2.61213880e-03, 2.01326592e-05]),\n",
       " array([4.39804651e-02, 1.56728328e-03, 8.05306368e-06]),\n",
       " array([3.51843721e-02, 9.40369969e-04, 3.22122547e-06]),\n",
       " array([2.81474977e-02, 5.64221981e-04, 1.28849019e-06]),\n",
       " array([2.25179981e-02, 3.38533189e-04, 5.15396076e-07]),\n",
       " array([1.80143985e-02, 2.03119913e-04, 2.06158430e-07]),\n",
       " array([1.44115188e-02, 1.21871948e-04, 8.24633721e-08]),\n",
       " array([1.15292150e-02, 7.31231688e-05, 3.29853488e-08]),\n",
       " array([9.22337204e-03, 4.38739013e-05, 1.31941395e-08]),\n",
       " array([7.37869763e-03, 2.63243408e-05, 5.27765581e-09]),\n",
       " array([5.90295810e-03, 1.57946045e-05, 2.11106233e-09]),\n",
       " array([4.72236648e-03, 9.47676268e-06, 8.44424930e-10]),\n",
       " array([3.77789319e-03, 5.68605761e-06, 3.37769972e-10])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ccf4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
